---
title: "linear model from Web"
author: "Destiny Calvillo"
date: "Summer 2021"
output:
   html_document:
         toc: true
         toc_depth: 5
        
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Read about the data from the website where it is staged.  Then form three regression models; Model1 is SIMS~ARM, Model2 is SIMS~GRIP, and Model3 is SIMS~ARM+GRIP. For each model find a 95% prediction interval of SIMS given a value of 94  for GRIP and 88 for ARM. Compare Model1 with Model3 using anova. Write it up in a markdown document, push the project up to your github account and submit it back to canvas as link. 

 


```{r include=FALSE}
require(tidyverse)
require(tigerstats)
require(rgl)
require(knitr)

```

```{r}
data <- read.csv(file="https://onlinestatbook.com/case_studies_rvls/physical_strength/data.txt",sep="",header=TRUE)  

```

## Model 1 SIM~ARMS

### scatterplot

```{r}
basicNN <- ggplot(data,aes(y=SIMS,x=ARM))
```
```{r}
basicNN + geom_point()
```

The Y-axis is SIMS and the X-axis is ARM. This plot shows that there is a positive linear correlation. It displays a positive relationship between ARM and SIMS.

### Numerical results

```{r}
cor(SIMS~ARM,data=data)
```

Above is the value of correlation, the value is 0.68. Since the value is a positive number, we should expect the sea of points to go uphill towards the right. We can also verify this in the scatter-plots from earlier.

### Inferential  (Build model.1)

```{r}
model.1 <- lm(SIMS~ARM,data=data)
summary.lm(model.1)
```

For the inferential results, we can see that the Adjusted R-Square is bigger, which means that more errors were reduced. To calculate SIMS based on ARM strength, we would use the equation of a line. The equation that best fits this is SIMS= -4.1 + 0.05 * R. The formula needed is y= mx + b to create the corresponding line. The Adjusted R-squared is the number to look at, which shows that the error was reduced by an estimated 47% or 0.467. Also, the prediction interval is between 1.226. There is a 145 degrees of freedom, which indicates the amount of data points or dots that there are in the plot.

#### Predict at target point

```{r}
newdata = data.frame(GRIP = 94, ARM = 88)
predict(model.1, newdata, interval = "prediction")
```

Above is the prediction interval given the targeted points. Meaning that it shows how far one point varies from the other. Furthermore, we'd end up with an approx amount of 2.3 if we were to subtract the upper and fit. 

#### scatterplot with model fit
 
```{r}
basicNN + geom_point( ) + geom_smooth(method=lm)
```   

Just by simply looking at the plot, it appears that the value of the Y-intercept would be around 1 or 1.25. The dots presented are apart of the regression line which was formed using the formula of a line. To calculate SIMS based on ARM strength, we would use the equation of a line. The equation that best fits this is SIMS= -4.1 + 0.05 * R. The formula needed is y= mx + b to create the corresponding line. Each point represents an output of the standard deviation within the normal distribution.

## Model 2 SIM~GRIP

### Now add in scatterplot

```{r}
basicNN <- ggplot(data,aes(y=SIMS,x=GRIP))
```
```{r}
basicNN + geom_point()
```

The Y-axis is SIMS and the X-axis is GRIP. This plot shows that there is a positive linear correlation. It displays a positive relationship between GRIP and SIMS.

### Numerical results 

```{r}
cor(SIMS~GRIP,data=data)
```

Above is the value of the correlation, which is an estimated 0.64. Since the value is a positive number, we should expect the group of points to go towards the right. The higher the correlation means the closer the points are together. 

### Inferential  (Build model.2)
  
```{r}
model.2 <- lm(SIMS~GRIP,data=data)
summary.lm(model.2)
```

For the inferential results, we can see that the Adjusted R-Square is 0.4053. The Adjusted R-squared is the number to look at, which shows that the error was reduced by an estimated 40% or 0.4053. To calculate SIMS based on     GRIP strength, we would use the equation of a line. The formula needed is y= mx + b to create the corresponding line. There is a 145 degrees of freedom, which indicates the amount of data points or dots that there are in the plot.

#### predict model.2 at target point

```{r}
predict(model.2, newdata, interval = "prediction")
predict(model.2, newdata, interval = "confidence")
```

The first line is the prediction interval, and the second is the confidence interval. It appears that the bounds of the confidence interval are much tighter than the bounds of the prediction interval. The prediction interval has to do with where we're predicting the next point to land/fall. The confidence interval is a confidence of where the line goes, which is between an estimated -0.8 to -0.28. 

Above is the prediction interval given the targeted points. Meaning that it shows how far one point varies from the other. We are 95% confident that the prediction is greater than -3.19 and less than 2.94.

#### now add the model fit to our plot for model.2
  
```{r}
basicNN + geom_point( ) + geom_smooth(method=lm)
``` 

It appears that the value of the Y-intercept would be around 1. The dots presented are apart of the regression line which was formed using the formula of a line. To calculate SIMS based on GRIP strength, we would use the equation of a line. The equation that best fits this is SIMS= -4.1 + 0.45 * GRIP. The formula needed is y= mx + b to create the corresponding line. Each point represents an output of the standard deviation within the normal distribution.

## Model 3 SIM~ARM+GRIP

### Numerical results (cor)

```{r}
cor(SIMS~ARM + GRIP,data=data)
```

Above is the value of the correlation, which is an estimated 0.73. Since the value is a positive number, we should expect the group of points to go towards the right if we were to conduct a scatterplot. The higher the correlation means the closer the points are together.  
  
### Inferential  (Build 2-dimentional model.3)

```{r}
model.3 <- lm(SIMS~ARM + GRIP,data=data)
summary.lm(model.3)
```

For the inferential results, we can see that the Adjusted R-Square is 0.5358. The Adjusted R-squared is the number to look at, which shows that the error was reduced by an estimated 54%. There is a 144 degrees of freedom, which indicates the amount of data points or dots that there are in the plot. The p-value of model 3 is significantly small, which leads us to assume that we can reject the null hypothesis in favor of the alternative.

#### predict model.3 at target point
 
```{r}
predict(model.3, newdata, interval = "prediction")
``` 

Above is the prediction interval given the targeted points. Meaning that it shows how far one point varies from the other.

## Comparing nested models ANOVA Test

### Model.1 vs Model.3

```{r}
anova(model.1,model.3)
```

Model 1 is nested in Model 3, since Model 1 is using ARM and Model 3 is using ARM (and GRIP). So, everything in Model 1 is also in Model 3.

The P-value is 0.00000499. The results are unlikely to occur by chance. The null hypothesis is rejected in favor of the alternative. The residual degrees of freedom is 145. All the errors together add up to 217. The errors were reduced by 29.45. This is saying that Model 2 is better than Model 1 because more errors were corrected.

### Model.2 vs Model.3

```{r}
anova(model.2,model.3)
```

Model 2 is nested in Model 3, since Model 2 is using GRIP and Model 3 is using GRIP (and ARM). So, everything in Model 2 is also in Model 3.

The P-value is 0.000000001495. The results are unlikely to occur by chance. The null hypothesis is rejected in favor of the alternative. The residual degrees of freedom is 145. All the errors together add up to 243.07. The errors were reduced by 54.639. This is saying that Model 2 is better than Model 1 because more errors were corrected.

## Informally compare Model.1 with model.2

```{r}
anova(model.1,model.2)
```

The one with the smaller sum of residual squares is better than the one with a bigger amount. There is a significant difference between the sum of squares between the two, with Model 1 having a total of 217. 88 and Model 2 having a total of 243.07. Here we can see that Model 2 has a bigger amount, which makes it an overall better model.
Furthermore, in the scatter-plots alone, we can simply see that the points are more closer to each other in Model 2 than in Model 1. Yet, once we determined the numerical results we seen that the Model 2 correlation was a bit smaller than the Model 1 correlation. In the inferential results, we see that Model 2 wasn't as good as Model 1 since the standard deviation is larger. 
There is a difference between the Multiple R-squared and adjusted R-squared as well. The Adjusted R-squared is a measure of how much of the variability in the response variable is explained by the explanatory variable. 0.467 is the adjusted R-squared for SIMS~ARM. 0.4053 is the adjusted R-squared for SIMS~GRIP.     
